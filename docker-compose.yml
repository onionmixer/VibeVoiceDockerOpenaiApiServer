# docker-compose.yml
# VibeVoice OpenAI API Server - x86_64 (NVIDIA CUDA)

services:
  vibevoice-api:
    build:
      context: ..
      dockerfile: ./VibeVoiceDockerOpenaiApiServer/Dockerfile
      args:
        TARGETARCH: amd64
    image: vibevoice-openai-api:latest
    container_name: vibevoice-openai-api
    ports:
      - "${API_PORT:-8899}:8080"
    environment:
      # Device settings
      - DEVICE=${DEVICE:-cuda}
      - ATTN_IMPLEMENTATION=${ATTN_IMPLEMENTATION:-sdpa}
      # Model paths (inside container)
      - ASR_MODEL_PATH=/models/VibeVoice-ASR
      - TTS_MODEL_PATH=/models/VibeVoice-Realtime-0.5B
      - VOICES_PATH=/models/voices
      # Service toggles
      - ASR_ENABLED=${ASR_ENABLED:-true}
      - TTS_ENABLED=${TTS_ENABLED:-true}
      # Model settings
      - ASR_DTYPE=${ASR_DTYPE:-float16}
      - TTS_DTYPE=${TTS_DTYPE:-float16}
      - BATCH_SIZE=${BATCH_SIZE:-1}
      # TTS settings
      - TTS_CFG_SCALE=${TTS_CFG_SCALE:-1.5}
      - TTS_INFERENCE_STEPS=${TTS_INFERENCE_STEPS:-5}
      - DEFAULT_VOICE=${DEFAULT_VOICE:-carter}
      # TTS model selection: "0.5b", "1.5b", or "both"
      - TTS_MODEL_TYPE=${TTS_MODEL_TYPE:-0.5b}
      - TTS_1_5B_MODEL_PATH=/models/VibeVoice-1.5B
      - TTS_1_5B_CFG_SCALE=${TTS_1_5B_CFG_SCALE:-1.3}
      - TTS_1_5B_INFERENCE_STEPS=${TTS_1_5B_INFERENCE_STEPS:-10}
    volumes:
      # External model directory mount (required)
      - ${MODEL_DIR:-./models}:/models:ro
      # HuggingFace cache (optional, for auto-download)
      - ${HF_CACHE:-~/.cache/huggingface}:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      start_period: 120s
      retries: 3

networks:
  default:
    name: vibevoice-network
